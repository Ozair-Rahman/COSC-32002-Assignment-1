{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from nltk.corpus import treebank\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /Users/ozairrahman/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download the Penn Treebank dataset\n",
    "nltk.download('treebank')\n",
    "\n",
    "# Load the dataset\n",
    "sentences = treebank.sents()\n",
    "corpus = [' '.join(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input sequences\n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i + 1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences\n",
    "max_sequence_length = max(len(x) for x in input_sequences)\n",
    "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictors and label\n",
    "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ozairrahman/miniforge3/envs/Lmao/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 106ms/step - accuracy: 0.0556 - loss: 7.2827\n",
      "Epoch 2/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 109ms/step - accuracy: 0.1281 - loss: 6.2461\n",
      "Epoch 3/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 107ms/step - accuracy: 0.1647 - loss: 5.6673\n",
      "Epoch 4/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 107ms/step - accuracy: 0.1911 - loss: 5.2028\n",
      "Epoch 5/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 110ms/step - accuracy: 0.2149 - loss: 4.7979\n",
      "Epoch 6/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 107ms/step - accuracy: 0.2407 - loss: 4.4485\n",
      "Epoch 7/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 109ms/step - accuracy: 0.2697 - loss: 4.1147\n",
      "Epoch 8/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 109ms/step - accuracy: 0.3037 - loss: 3.8072\n",
      "Epoch 9/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 107ms/step - accuracy: 0.3417 - loss: 3.5222\n",
      "Epoch 10/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 107ms/step - accuracy: 0.3799 - loss: 3.2611\n",
      "Epoch 11/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 106ms/step - accuracy: 0.4184 - loss: 3.0093\n",
      "Epoch 12/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 107ms/step - accuracy: 0.4560 - loss: 2.8001\n",
      "Epoch 13/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 107ms/step - accuracy: 0.4888 - loss: 2.6053\n",
      "Epoch 14/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 106ms/step - accuracy: 0.5169 - loss: 2.4326\n",
      "Epoch 15/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 107ms/step - accuracy: 0.5484 - loss: 2.2573\n",
      "Epoch 16/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 106ms/step - accuracy: 0.5757 - loss: 2.1098\n",
      "Epoch 17/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 107ms/step - accuracy: 0.6017 - loss: 1.9753\n",
      "Epoch 18/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 107ms/step - accuracy: 0.6260 - loss: 1.8437\n",
      "Epoch 19/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 107ms/step - accuracy: 0.6438 - loss: 1.7426\n",
      "Epoch 20/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 106ms/step - accuracy: 0.6685 - loss: 1.6277\n",
      "Epoch 21/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 108ms/step - accuracy: 0.6874 - loss: 1.5298\n",
      "Epoch 22/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 108ms/step - accuracy: 0.7037 - loss: 1.4581\n",
      "Epoch 23/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m296s\u001b[0m 106ms/step - accuracy: 0.7230 - loss: 1.3608\n",
      "Epoch 24/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 107ms/step - accuracy: 0.7348 - loss: 1.2984\n",
      "Epoch 25/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 108ms/step - accuracy: 0.7509 - loss: 1.2219\n",
      "Epoch 26/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 111ms/step - accuracy: 0.7641 - loss: 1.1521\n",
      "Epoch 27/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m311s\u001b[0m 112ms/step - accuracy: 0.7750 - loss: 1.1024\n",
      "Epoch 28/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 111ms/step - accuracy: 0.7864 - loss: 1.0436\n",
      "Epoch 29/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 108ms/step - accuracy: 0.7973 - loss: 0.9907\n",
      "Epoch 30/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m307s\u001b[0m 110ms/step - accuracy: 0.8063 - loss: 0.9502\n",
      "Epoch 31/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 108ms/step - accuracy: 0.8179 - loss: 0.9058\n",
      "Epoch 32/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 109ms/step - accuracy: 0.8249 - loss: 0.8701\n",
      "Epoch 33/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 109ms/step - accuracy: 0.8338 - loss: 0.8181\n",
      "Epoch 34/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 106ms/step - accuracy: 0.8400 - loss: 0.7914\n",
      "Epoch 35/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 109ms/step - accuracy: 0.8470 - loss: 0.7543\n",
      "Epoch 36/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m303s\u001b[0m 109ms/step - accuracy: 0.8519 - loss: 0.7293\n",
      "Epoch 37/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 109ms/step - accuracy: 0.8558 - loss: 0.7054\n",
      "Epoch 38/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 110ms/step - accuracy: 0.8644 - loss: 0.6701\n",
      "Epoch 39/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 110ms/step - accuracy: 0.8689 - loss: 0.6399\n",
      "Epoch 40/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m305s\u001b[0m 110ms/step - accuracy: 0.8729 - loss: 0.6256\n",
      "Epoch 41/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m306s\u001b[0m 110ms/step - accuracy: 0.8779 - loss: 0.6050\n",
      "Epoch 42/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 105ms/step - accuracy: 0.8826 - loss: 0.5822\n",
      "Epoch 43/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m294s\u001b[0m 106ms/step - accuracy: 0.8879 - loss: 0.5642\n",
      "Epoch 44/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m292s\u001b[0m 105ms/step - accuracy: 0.8913 - loss: 0.5438\n",
      "Epoch 45/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m295s\u001b[0m 106ms/step - accuracy: 0.8943 - loss: 0.5297\n",
      "Epoch 46/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 107ms/step - accuracy: 0.8979 - loss: 0.5071\n",
      "Epoch 47/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 107ms/step - accuracy: 0.8990 - loss: 0.4937\n",
      "Epoch 48/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 107ms/step - accuracy: 0.9006 - loss: 0.4835\n",
      "Epoch 49/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 107ms/step - accuracy: 0.9049 - loss: 0.4631\n",
      "Epoch 50/50\n",
      "\u001b[1m2781/2781\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m298s\u001b[0m 107ms/step - accuracy: 0.9068 - loss: 0.4577\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x17c351f30>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(total_words, 100, input_length=max_sequence_length - 1),\n",
    "    tf.keras.layers.LSTM(100),\n",
    "    tf.keras.layers.Dense(total_words, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_2.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Lmao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
